---
layout: post
title: Implement and Apply a Multiclass Support Vector Machine (SVM) Classifier -- Exercise
---

I am currently listening to the lectures for 
[CS231n: Convolutional Neural Networks for Visual Recognition](https://www.youtube.com/watch?v=vT1JzLTH4G4&list=PL3FW7Lu3i5JvHM8ljYj-zLfQRF3EO8sYv&index=1)
I will post my solutions to the [programming exercises](http://cs231n.github.io/) attached with this course here.

In this exercise we are asked to train a loss function for the SVM classifier 
on the CIFAR-10 dataset. 

### Linear Classifier for Images

According to [lecture notes](http://cs231n.github.io/linear-classify/), we define the 
score function as

$$
\begin{align*}
  f(x_i,W) = Wx_i
\end{align*}
$$

In the CIFAR-10 example, *x<sub>i</sub>* is 3073x1 - with the dimension holding the constant 1.

In an expanded format this is what the matrix multiplication will look like:

$$
\begin{align*}
  \begin{pmatrix}
W_{0,0} & W_{0,1} & \dots & W_{0,3073} \\
W_{1,0} & W_{1,1} & \dots & W_{1,3073} \\
\vdots & \vdots & \ddots & \vdots \\
W_{9,0} & W_{9,1} & \dots & W_{9,3073} \\
\end{pmatrix}
\begin{pmatrix}
X_{i,0} \\
X_{i,1} \\
\vdots \\
X_{i,3072} \\
1
\end{pmatrix}
=
\begin{pmatrix}
f(i,0) \\
f(i,1) \\
\vdots \\
f{i,9}
\end{pmatrix}
\end{align*}
$$

where *f(i,0)* is the score for image *i* belonging to class 0, *f(i,1)* is the 
score for image *i* belonging to class 1, and so on.

### Multiclass SVM Loss Function

The SVM loss function is setup so that the score for *f(i,y<sub>i</sub>)* has the highest 
score, where *y<sub>i</sub>* is the true class for image *i*. More precisely, the 
multiclass SVM loss for for *i*-th example is

$$
\begin{align*}
L_i = \sum_{j \neq y_i} \text{max}(0, f(i,j) - f(i,y_i) + \Delta)
\end{align*}
$$

Here is a naive way to calculate the loss for all images in the training set.

```python
# compute the loss
num_classes = W.shape[1]
num_train = X.shape[0]
loss = 0.0

for i in range(num_train):
    # i is the image under consideration
    scores = X[i].dot(W)
    correct_class_score = scores[y[i]]
    for j in range(num_classes):
        # j is the class
        if j == y[i]:
            continue
        margin = scores[j] - correct_class_score + 1  # note delta = 1
        if margin > 0:
            loss += margin
```

#### How to calculate the gradient for the loss

The full Multiclass SVM loss is given by

$$
\begin{align*}
L = \frac{1}{N}\sum_i L_i + \uplambda*||W||^2
\end{align*}
$$

Where *N* is the number of images in the training set, $$\begin{align*}
\uplambda
\end{align*}
$$ is the weighing hyperparameters, *||W||<sup>2</sup>* is the square of the L2-norm of 
the weight matrix *W*. 



To see the full assignment, see [here](https://github.com/usmanr149/CS231n/blob/master/assignment1/knn.ipynb).